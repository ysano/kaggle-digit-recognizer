{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.utils import plot_model, to_categorical\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "#resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "#tf.config.experimental_connect_to_cluster(resolver)\n",
    "#tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples =  42000\n",
      "X_train shape: (42000, 28, 28, 1)\n",
      "Y_train shape: (42000, 10)\n",
      "Quiz examples =  28000\n",
      "X_quiz shape: (28000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "def load_dataset():\n",
    "    train = pd.read_csv('../input/digit-recognizer/train.csv')\n",
    "    label = train.pop('label')    \n",
    "    return train, label, label.nunique()\n",
    "\n",
    "X_train_orig, Y_train_orig, classes = load_dataset()\n",
    "m = X_train_orig.shape[0]\n",
    "\n",
    "def load_quizset():\n",
    "    quiz = pd.read_csv('../input/digit-recognizer/test.csv')\n",
    "    return quiz\n",
    "\n",
    "X_quiz_orig = load_quizset()\n",
    "mq = X_quiz_orig.shape[0]\n",
    "\n",
    "# Reshape and Normalize image vectors\n",
    "X_train = X_train_orig.to_numpy().reshape((-1,28,28,1))/255.0\n",
    "X_quiz = X_quiz_orig.to_numpy().reshape((-1,28,28,1))/255.0\n",
    "\n",
    "# one hot encoding\n",
    "Y_train = to_categorical(Y_train_orig.to_numpy())\n",
    "\n",
    "print(\"Training examples = \", str(m))\n",
    "print(\"X_train shape: \" + str(X_train.shape))\n",
    "print(\"Y_train shape: \" + str(Y_train.shape))\n",
    "print(\"Quiz examples = \", str(mq))\n",
    "print(\"X_quiz shape: \" + str(X_quiz.shape))\n",
    "\n",
    "# each pic 28x28x1=784\n",
    "# train 42000 pic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[np.isnan(X_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e5d9b87c88>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0][:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import PIL.Image. The use of `array_to_img` requires PIL.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-55c10e053ce7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_to_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_gen\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[1;31m#print(data.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf21-gpu\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36marray_to_img\u001b[1;34m(x, data_format, scale, dtype)\u001b[0m\n\u001b[0;32m     50\u001b[0m                               \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                               \u001b[0mscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m                               dtype=dtype)\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf21-gpu\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\u001b[0m in \u001b[0;36marray_to_img\u001b[1;34m(x, data_format, scale, dtype)\u001b[0m\n\u001b[0;32m    243\u001b[0m     \"\"\"\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpil_image\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m         raise ImportError('Could not import PIL.Image. '\n\u001b[0m\u001b[0;32m    246\u001b[0m                           'The use of `array_to_img` requires PIL.')\n\u001b[0;32m    247\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Could not import PIL.Image. The use of `array_to_img` requires PIL."
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHIAAABvCAYAAAAwlZQ4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAABYElEQVR4nO3UwU0DUQxAwf2IEsKZ7b+WpIicoQfTQFBYKRHwNHO1D5ae5DUzG//fy28fwGMIGSFkhJARQkYIGfF6ZPl0Os2+7086hXsul8vnzLzdmh0Kue/7dj6fH3MVh621rt/NvNYIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjFgz8/PltT62bbs+7xzueJ+Zt1uDQyH5u7zWCCEjhIwQMkLICCEjhIwQMkLIiC8Hohp/BhBaQAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# augmentation generator\n",
    "train_image_gen = ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    #brightness_range=(0.3,2),\n",
    "    shear_range=5,\n",
    "    zoom_range=0.1,\n",
    "    validation_split=0.2\n",
    "    )\n",
    "train_image_gen.fit(X_train)\n",
    "\n",
    "# Generally only apply data augmentation to the training examples.\n",
    "val_image_gen = ImageDataGenerator()\n",
    "\n",
    "# check results\n",
    "data_gen = train_image_gen.flow(X_train,seed=130)\n",
    "plt.figure(figsize=(10,10))\n",
    "i=0\n",
    "for data in data_gen[1]:\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)    \n",
    "    plt.imshow(image.array_to_img(data_gen[0][i]))\n",
    "    #print(data.shape)\n",
    "    i = i+1\n",
    "    if i > 24:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img check\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(image.array_to_img(X_train[i]))\n",
    "    plt.xlabel(np.argmax(Y_train[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "* ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(input_shape,classes):\n",
    "    \"\"\"\n",
    "    input_shape: height, width, channels as tuple\n",
    "    \"\"\"       \n",
    "    # input placeholder\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    # zero padding\n",
    "    X = ZeroPadding2D((3,3))(X_input)\n",
    "    \n",
    "    # Stage1 CNV -> BN -> RELU -> MAXPOOL -> Dropout\n",
    "    X = Conv2D(32,(7,7), strides=(1,1), name='conv1a')(X)\n",
    "    #X = BatchNormalization(axis=3,name='bn_conv1a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(64,(7,7), strides=(1,1), name='conv1b')(X)\n",
    "    #X = BatchNormalization(axis=3,name='bn_conv1b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = MaxPooling2D((2,2))(X)\n",
    "    X = Dropout(0.3)(X)\n",
    "    \n",
    "    #X_shortcut = X    \n",
    "\n",
    "    # Stage2 CNV -> BN -> RELU -> MAXPOOL -> Dropout\n",
    "    X = Conv2D(128,(5,5), strides=(1,1), name='conv2a')(X)\n",
    "    #X = BatchNormalization(axis=3,name='bn_conv2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(256,(5,5), strides=(1,1), name='conv2b')(X)\n",
    "    #X = BatchNormalization(axis=3,name='bn_conv2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = MaxPooling2D((2,2), strides=(2,2))(X)\n",
    "    X = Dropout(0.3)(X)\n",
    " \n",
    "    #X_shortcut = Conv2D(128,(3,3), strides=(1,1), padding='valid', name='conv2')(X_shortcut)\n",
    "    #X_shortcut = BatchNormalization(axis=3,name='bn_conv2')(X_shortcut)\n",
    "    #X = Add()([X,X_shortcut])\n",
    "    #X = LeakyReLU()(X)\n",
    "       \n",
    "    # Flatten X + FullyConnected\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc'+str(classes))(X)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='MyModel')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model(X_train.shape[1:],classes).summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model(X_train.shape[1:],classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate reduction\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_categorical_accuracy', \n",
    "                                            patience=5, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.3, \n",
    "                                            min_lr=1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
    "#strategy = tf.distribute.MirroredStrategy()\n",
    "#with strategy.scope():\n",
    "BATCH_SIZE=4096\n",
    "EPOCHS=1000\n",
    "mymodel = model(X_train.shape[1:],classes)\n",
    "mymodel.compile(optimizer=Adam(),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['categorical_accuracy','categorical_crossentropy'])\n",
    "history = mymodel.fit(train_image_gen.flow(x=X_train,y=Y_train,batch_size=BATCH_SIZE),\n",
    "                      #x=X_train, y=Y_train, batch_size=BATCH_SIZE,\n",
    "                      epochs=EPOCHS, shuffle=True,\n",
    "                      #validation_split=0.2,\n",
    "                      validation_data=val_image_gen.flow(x=X_train,y=Y_train,batch_size=BATCH_SIZE),\n",
    "                      #validation_data=Y_train,\n",
    "                      callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_categorical_crossentropy',patience=16,restore_best_weights=True),\n",
    "                                learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['categorical_accuracy']\n",
    "val_acc = history.history['val_categorical_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate with \"train\" datatset\n",
    "* list predict error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = mymodel.predict(X_train)\n",
    "Y_pred_classes = np.argmax(Y_pred,axis=1)\n",
    "Y_train_classes = np.argmax(Y_train,axis=1)\n",
    "\n",
    "errors = (Y_pred_classes - Y_train_classes !=0)\n",
    "Y_pred_errors = Y_pred_classes[errors]\n",
    "Y_train_errors = Y_train_classes[errors]\n",
    "X_train_errors = X_train[errors]\n",
    "#plt.imshow(X_train_errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error img in train\n",
    "plt.figure(figsize=(14,14))\n",
    "for i in range(len(Y_pred_errors)):\n",
    "    plt.subplot(10,25,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(image.array_to_img(X_train_errors[i]))\n",
    "    plt.xlabel(\"{} : {}\".format(Y_pred_errors[i],Y_train_errors[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_quiz = mymodel.predict(X_quiz)\n",
    "Y_sub = np.argmax(Y_quiz,axis=1)\n",
    "Y_sub = pd.Series(Y_sub,name=\"Label\")\n",
    "submission = pd.concat([pd.Series(range(1,28001),name='ImageId'),Y_sub],axis=1)\n",
    "submission.to_csv(\"submission.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
